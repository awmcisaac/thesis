%! TeX root = ../charles/en/thesis.tex
\chapter{Results}
\label{chap:results}

In this chapter we evaluate the performance of post-pretraining the Merlot
Reserve model on our proposed dataset from \cref{chap:setup}. We test
downstream performance on STAR~\citep{wu2021star} and
NExT-QA~\citep{xiao2021nextqa}, and analyse some of the choices we made in our
dataset design process. We finish with a comparison
to~\citep{bagad2023testoftime}.

\section{Results on STAR}
\label{sec:star_results}

We report zero-shot performance of our model compared to the original Merlot Reserve
model in \cref{tab:star_ppt}. We find that the performance is slightly worse,
except for prediction and feasibility questions.

\begin{table}[t]
	\centering
	\caption{STAR downstream performance}
	\label{tab:star_ppt}
	\begin{tabular}{lccccc}
        \toprule
        \multicolumn{1}{c}{}        & \multicolumn{4}{c}{Question Types}        & \multicolumn{1}{c}{} \\
                                      \cmidrule(){2-5}
                                    & I           & S        & P          & F           & Mean \\
        \cmidrule(r){1-1}             \cmidrule(){2-5}                          \cmidrule(l){6-6}
    Merlot Reserve (val)        & 43.12       & 42.33    & 43.27      & 47.14       & 43.01 (43.97) \\
%	Swapped before/after		&			  & 42.92    &			  &				& \\
%	Masked temporal expressions &			  & 50.86    &			  &				& \\
%	Shuffled frames				& 42.08		  & 42.58	 & 47.28	  & 49.20		& 38.47 \\
%    \cmidrule(r){1-1}             \cmidrule(){2-5}                          \cmidrule(l){6-6}
%	5500 steps					& 35.86		  & 40.43	 & 46.79	  & 45.10		& 39.77 \\
%	Swapped before/after		&			  & 39.88	 &			  &				& \\
%	Masked temporal expressions &			  & 43.08    &			  &				& \\
%	Shuffled frames				& 36.27		  & 37.90	 & 51.52	  & 39.39		& 38.47 \\
%    \cmidrule(r){1-1}             \cmidrule(){2-5}                          \cmidrule(l){6-6}
%	19500 steps					& 39.16		  & 41.83    & 48.55	  & 45.31		& 41.76 \\
%	Swapped before/after		&			  & 41.27	 &			  &				& \\
%	Masked temporal expressions &			  & 42.30    &			  &				& \\
%	Shuffled frames				& 39.32		  & 42.30	 & 52.72	  & 49.18		& 42.68 \\
%    \cmidrule(r){1-1}             \cmidrule(){2-5}                          \cmidrule(l){6-6}
%	22500 steps					& 40.95		  & 43.20    & 50.32	  & 48.16		& 43.41 \\
%	Swapped before/after		& 			  &	42.89    &			  &				& \\
%	Masked temporal expressions &			  & 43.08    &			  &				& \\
%	Shuffled frames				& 41.83		  & 43.53	 & 52.88	  & 52.24		& 44.38 \\
%	\midrule
%	\midrule
%	\multicolumn{6}{c}{Performance degrades with masking only temporal expressions} \\
%	20000 steps					& 30.82		  &	35.02	 & 38.14	  &	37.76		& 34.07 \\
%	Swapped before/after		&			  &	34.69	 &			  &				& \\
%	Masked temporal expressions	&			  &			 &			  &				& \\
%	Shuffled frames				&   &  &   &  & \\
%    \cmidrule(r){1-1}             \cmidrule(){2-5}                          \cmidrule(l){6-6}
%	41000 steps					& 30.86		  & 34.69    & 37.82      & 38.57       & 33.94 \\
%	Swapped before/after		&			  & 34.33	 &		      &				& \\
%	Masked temporal expressions &			  & 43.20	 &			  &				& \\
%	Shuffled frames				& 31.15		  & 34.41	 & 37.18	  & 38.16		& 33.81 \\
%	\midrule
%	\midrule
%	\multicolumn{6}{c}{Mixed temporal sparse} \\
%	25000 steps					& 38.99 & 40.3 & 48.2 & 51.2 & 41.3 \\
%	Swapped before/after		&		& 39.65 &	&		& \\
%	Shuffled frames				& 38.41 & 40.52 & 49.2 & 50.2 & 41.2 \\
%	\midrule
	\midrule
%		\multicolumn{6}{c}{Updated charades\_parser} \\
		%Ours (13500 steps)			& 39.41 & 39.79 & 47.76 & 46.94 & 40.86 \\
		%Swapped before/after		&		& 40.83	&		&		&	\\
		%Shuffled frames				&  &  &  &  &  \\
		\midrule
		Ours (22500 steps)			& 39.12 & 40.18 & 48.88 & 48.16 & 41.14 \\
%		Swapped before/after		&		&  &		&		&	\\
%		Shuffled frames				&  &  &  &  &  \\
        \bottomrule
%		Interaction Accuracy: 0.39115929941618016
%Sequence Accuracy: 0.401840490797546
%Prediction Accuracy: 0.48878205128205127
%Feasibility Accuracy: 0.4816326530612245
%Overall Accuracy: 0.41138348830656524
	\end{tabular}
\end{table}


%TODO: rewrite
We also test the probing experiments from \cref{chap:probe}. Results are in
\cref{tab:probe_final}. There is little change except in the masking temporal
expressions, which shows improvement in predicting before/after relations.

\begin{table}[t]
	\centering
	\caption{Probing Sequence Questions. Comparisons in brackets are compared
	to sequence values in \cref{tab:star_ppt}}
	\label{tab:probe_final}
	\begin{tabular}{lccc}
	\toprule
	Model & Swap ($\downarrow$) & Shuffle Frames ($\downarrow$) & Mask ($\uparrow$) \\
        \cmidrule(r){1-1}             \cmidrule(){2-4}
		Merlot Reserve & 42.92 (+0.59) & 42.58 (+0.25)  & 50.86 \\
%		VideoCLIP & & & \\
		Ours & 40.66 (+0.48) & 40.88 (+0.70) & 56.97 \\
	\bottomrule
	\end{tabular}
\end{table}

\section{NExT-QA Results}
\label{sec:nextqa_results}
%NExT-QA results (\cref{tab:nextqa}). Questions are interesting, generally a bit of a drop, but huge loss in performance for counting questions.

To test the generalisability of our approach to a wider range of temporal
relations, and a different domain, we also test zero-shot on NExT-QA. As in
\cref{sec:mres_zs}, we convert NExT-QA questions into statements to minimise
distribution drift. Since each question is hand-written and does not follow a
strict template for question types, we use a generative \acrshort{llm} to
convert from questions to masked statements. We follow the approach in
\citet{zellers2022mreserve} for generating statements for
MSRVTT-QA~\citep{xu2016msr-vtt} questions, by providing a prompt for each
question type. We use Mistral-7B-Instruct~\cite{jiang2023mistral}, an
\acrshort{llm}which has been finetuned to better respond to instructional
prompts (see~\citet{ouyang2022instructgpt}). For each question, we provide a
different prompt depending on the question type, which includes an instruction
of the task, three examples taken from the training set with hand-written
statement conversions, and finally the question which is to be converted. An example
for temporal next (TN) questions is shown below:

\begin{verbatim}
system: "You are a helpful assistant. The user will give an input
        question, and you will respond with the question in the
        form of a statement, giving space for an answer in the
        form of an underscore."
user: "what does the girl do after placing the mop down"
assistant: "the girl _ after placing the mop down"
user: "how does the child react after falling over"
assistant: "the child _ after falling over"
user: "what did the boy do after he stopped playing the drums the 
      second time"
assistant: "the boy _ after he stopped playing the drums the 
           second time"
user: ${question}
assistant: 
\end{verbatim}

We confirm that the output is valid by checking that there is one mask token
per generated statement, and manually editing if there was not. We found 25
examples that had to be manually edited, predominantly for questions such as
asking to describe the colour of clothes worn by multiple people, where the
answer is actually the same for both people.

We show our results in \cref{tab:nextqa}. We compare the performance on Merlot Reserve
using our generated statements with using the existing questions and adding a mask
token at the end of the question, and observe overall better performance
using statements. We then evaluate our post-pretrained model on the whole NExT-QA
dataset, as well as the ATP\textsubscript{hard} subset.

\begin{table}[t]
	\centering
	\caption{NExT-QA Results on Merlot Reserve. Causal How, Causal Why,
	Temporal Current, Temporal Next, Temporal Previous, Descriptive Location,
	Descriptive Count, Descriptive Other}
	\label{tab:nextqa}
	\begin{tabular}{lccccccccc}
		\toprule
		\multicolumn{1}{c}{}  & \multicolumn{8}{c}{Question Types} & \multicolumn{1}{c}{}   \\
                                      \cmidrule(){2-9}
							  &  CH  &  CW  &  TC  &  TN  &  TP  &  DL  &  DC  &  DO  & Mean \\
%		\cmidrule(r){1-1}             \cmidrule(){2-9}						 \cmidrule(){10-10}
		\midrule
		Chance				  & \multicolumn{9}{c}{20.0} \\
		\midrule
		MReserve (val)        & 33.2 & 36.7 & 27.8 & 35.6 & 40.7 & 35.0 & 41.0 & 42.6 & 35.0 \\
		%Shuffled Frames		  & 33.5 & 35.7 & 28.9 & 36.0 & 36.9 & 35.0 & 40.0 & 38.9 & 34.6 \\
		With Questions		  & 35.3 & 34.0 & 29.8 & 31.4 & 30.8 & 15.8 & 34.8 & 25.9 & 32.2 \\
		\midrule
		ATP\textsubscript{hard}	&	28.9 & 27.5 & 29.8 & 25.8 &	17.2 &  	&      &      & 27.5 \\
		%Shuffled Frames		  & 29.7 & 27.7 & 30.0 & 24.7 & 24.1 &      &      &      & 27.6 \\
		\midrule
		% Sparse 20000 ATP	  &	23.2 & 25.8 & 26.4 & 21.7 &	10.3 &  	&      &      & 24.3 \\
		% Shuffled Frames		  & 23.2 & 26.2 & 27.0 & 20.6 & 10.3 &      &      &      & 24.3 \\
		% \midrule
		\bottomrule
	\end{tabular}
\end{table}

\section{Qualitative Examples}
\label{sec:qualresults}

Show some examples of predictions we get right, Merlot Reserve gets wrong,
(and reverse?).

\section{Expanding Temporal Relation Types}
\label{sec:expandtemprel}

We look at the effect of training on multiple relation types based on Allen's
Interval Algebra (\cref{sec:data}; \citet{allen1983interval}). We compare using
a subset of the relation types for non-overlapping relations, and their
inverses. In practice, this means using the \textit{before} and \textit{meets}
relations, and their inverses. Results are shown in \cref{tab:expandtemprel}.
We find that using a wider range of relations performs better/worse.

\begin{table}[t]
	\centering
	\caption{Comparison of number of temporal relations used.}
	\label{tab:expandtemprel}
	\begin{tabular}{lcc}
		\toprule
		& STAR (Sequence) & NExT-QA (ATP\textsubscript{hard}) \\
		\midrule
		Non-overlapping & 40.18 & TODO \\
		All relation types & & TODO \\
		\bottomrule
	\end{tabular}
\end{table}

We look at qualitative outputs. Compare examples which each version gets wrong.
Generalisability of the approach with NExT-QA.

\section{Selecting Annotation Method}
\label{sec:annot_method}

We also explore alternative approaches for creating the segments. Remember from
\cref{ssec:create_segs} that we split labels across three segments, with the
form \mbox{[X[:-1]~;~X[-1:]+$\tau$+Y[:1]~;~Y[1:]]}, combining action
annotations across segment boundaries. We experiment with creating segments
formed distinctly of the action annotation and temporal expression in different
segments, i.e. \mbox{[X;$\tau$;Y]}. We find that this significantly degrades
performance (\cref{tab:annot_method}), and hypothesise that this is due to the
shorter length of the temporal relation, often just a single token, which
differs significantly from the length of segments found in pre-training.

\begin{table}[t]
	\centering
	\caption{Annotation Method results on STAR}
	\label{tab:annot_method}
	\begin{tabular}{lcc}
		\toprule
		 & Sequence & All \\
		\midrule
		Combination & 40.18 & 41.14 \\
		Only temporal & 34.69 & 33.94 \\
		\bottomrule
	\end{tabular}
\end{table}


%TODO: explain this better
We further explore using more dense annotations, with multiple relations per
instance. We attempt to include as many relations as possible, with the
requirement that relations cannot overlap with one another in time.  Where
there is an overlap, there is a precedence order of relations: \textit{meets}
\textgreater~\textit{overlaps} \textgreater~\textit{starts}
\textgreater~\textit{finishes} \textgreater~\textit{during}
\textgreater~\textit{equals} \textgreater~\textit{precedes}. This ordering
prioritises relations that occur closer together, allowing for more relations
in a single instance.

Frames are selected based on $(X_{start}, X_{end}), (Y_{start}, Y_{end})$ and
the specific relation type. If a relation requires frames that intersect an
already selected frame, the relation is discarded. This is to keep a strict
relationship between actions and time relations. Once all relations have been
processed, any remaining frames up to 8 (the number of frames used in Merlot
Reserve) are selected uniformly at the beginning or end, depending on the time
before and after any relations. %Maybe more detail on exactly what is done here?

Each frame associated with a relation is annotated with the associated actions
$X$ and $Y$, along with a temporal indicator based on the specific relation
type.

For example, for a 30 second video, one relation may select two frames
at 11 and 17 seconds, based on the times of the relation's actions. If a second
relation requires frames at 15 and 19 seconds, this relation would be scrapped,
since the alignment of the text description to their respective frames becomes
impossible.

\section{Freezing Layers}

We test freezing different layers of the model, and find little difference
%TODO: table for these results


\section{Comparison to Test of Time}
\label{sec:tactcompare}

Different base model. They use VideoCLIP~\citep{xu2021videoclip}, which performs well,
but other models do not perform so well, e.g. Frozen~\citep{bain2021frozen}, 
VindLU~\citep{cheng2023vindlu}, CLIP4CLIP~\citep{luo2022clip4clip}. They hypothesise
that it may be because of number of frames input to the model. We use Merlot Reserve,
which has 8 frames compared to VideoCLIP's 32. Poor results on this would indicate
more frames is better for this task.

Real-world data. We use full clips rather than stitched together. We use wider range
of temporal relations (not just before/after).

\begin{table}[tp] 
    \centering 
    \caption{Test of Time results}
    \label{tab:tot_star} 
    \begin{tabular}{lccccc} 
        \toprule
        \multicolumn{1}{c}{}    & \multicolumn{4}{c}{Question Types}            & \multicolumn{1}{c}{} \\
                                    \cmidrule(){2-5}
                                & I           & S        & P          & F           & Mean \\
        \cmidrule(r){1-1}           \cmidrule(){2-5}                                    \cmidrule(l){6-6}
        VideoCLIP (val)         & 39.66       & 42.86    & 48.72      & 50.82       & 42.84 \\
		Charades TACT (val)		& 45.79		  & 51.28	 & 61.06	  & 60.00		& 50.89 \\
		Swapped before/after    &			  &	49.30	 &			  &				& \\
		Masked temporal exprs   &			  & 52.54    &			  &				& \\
		Shuffled videos			& 37.45		  & 38.29	 & 43.27	  & 44.49		& 38.87 \\
		Shuffled frames			& 45.25		  & 50.11    & 57.05      & 58.78		& 49.68 \\
        \cmidrule(r){1-1}           \cmidrule(){2-5}                                    \cmidrule(l){6-6}
		TEMPO TACT (val)		& 39.49		  & 39.88	 & 47.44	  & 46.33		& 40.86 \\
		Swapped before/after    &			  & 37.73    &			  &				& \\
		Masked temporal exprs   &			  & 57.53    &			  &				& \\
		Shuffled videos			& 34.15		  & 33.27	 & 39.26	  & 37.14		& 34.36 \\
		Shuffled frames			& 38.49		  & 38.09	 & 44.55	  & 42.25		& 39.08 \\
        \bottomrule
    \end{tabular} 
\end{table} 
