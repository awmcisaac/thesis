%%% A template for a simple PDF/A file like a stand-alone abstract of the thesis.

\documentclass[12pt]{article}

\usepackage[a4paper, hmargin=1in, vmargin=1in]{geometry}
\usepackage[a-2u]{pdfx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{textcomp}

\title{\textsc{Temporal Reasoning in Vision and Language Models}}
\date{December 2023}
\author{Andrew McIsaac\\ University of Trento}

\begin{document}
%% Do not forget to edit abstract.xmpdata.

\maketitle

\begin{abstract}
	Are vision and language models able to reason across time? We evaluate the
	performance of vision and language models (VLMs) on the task of video
	question answering, with a particular focus on their temporal reasoning
	abilities. We probe the STAR video QA dataset on two VLMs with data
	perturbation methods of text and video inputs, and find that models are
	generally unable to identify the meaning of before and after in sequential
	questions. We then ask how a model can effectively learn these temporal
	relations, and design a new dataset drawn from videos and annotations from
	the Charades dataset. We create annotations that include targeted hard
	negative examples for the contrastive loss objective of one VLM, Merlot
	Reserve, such that the model must adapt to learn temporal relations. We
	further explore how to model fine-grained temporal relationships, and
	evaluate the benefits. We find that our approach shows promising signs of
	improvement on tasks that require temporal understanding, although it gains
	little sensitivity to temporal relations when probed.
\end{abstract}

\end{document}
